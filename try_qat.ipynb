{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/keerthiv/deep_conv_lstm/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantAwareModel(\n",
       "  (conv1): Conv1d(\n",
       "    3, 16, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(\n",
       "    16, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(\n",
       "    in_features=32, out_features=10, bias=True\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
       "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (quant1): QuantStub(\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (dequant1): DeQuantStub()\n",
       "  (quant2): QuantStub(\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (dequant2): DeQuantStub()\n",
       "  (quant3): QuantStub(\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (dequant3): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization as quant\n",
    "from torch.quantization.observer import MovingAverageMinMaxObserver, default_weight_observer\n",
    "\n",
    "class CustomObserver(MovingAverageMinMaxObserver):\n",
    "    def calculate_qparams(self):\n",
    "        scale, _ = super().calculate_qparams()\n",
    "        zero_point = torch.tensor(0, dtype=torch.int32)\n",
    "        return scale, zero_point\n",
    "\n",
    "class QuantAwareModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantAwareModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveAvgPool1d((1))\n",
    "        self.fc = nn.Linear(32, 10)\n",
    "        \n",
    "        self.quant1 = quant.QuantStub()  # Quantizes the input\n",
    "        self.dequant1 = quant.DeQuantStub()  # Dequantizes the output\n",
    "        self.quant2 = quant.QuantStub()  # Quantizes the input\n",
    "        self.dequant2 = quant.DeQuantStub()  # Dequantizes the output\n",
    "        self.quant3 = quant.QuantStub()  # Quantizes the input\n",
    "        self.dequant3 = quant.DeQuantStub()  # Dequantizes the output\n",
    "        \n",
    "        self.int_output1 = None\n",
    "        self.int_output2 = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant1(x)  # Quantize the input\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dequant1(x)\n",
    "        x = self.quant2(x)  # Quantize the input\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dequant2(x)\n",
    "        print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.quant3(x)  # Quantize the input\n",
    "        print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        x = self.dequant3(x)  # Dequantize the output\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = QuantAwareModel()\n",
    "\n",
    "# Set the QAT configuration with custom observer forcing zero_point to 0\n",
    "model.qconfig = quant.QConfig(\n",
    "    activation=quant.FakeQuantize.with_args(observer=CustomObserver, quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine),\n",
    "    weight=quant.FakeQuantize.with_args(observer=default_weight_observer, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
    ")\n",
    "\n",
    "# Prepare the model for QAT\n",
    "quant.prepare_qat(model, inplace=True)\n",
    "\n",
    "# Move the model to GPU for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 1, Loss: 2.30914568901062\n",
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 2, Loss: 2.308565855026245\n",
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 3, Loss: 2.3078770637512207\n",
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 4, Loss: 2.3063342571258545\n",
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 5, Loss: 2.3044683933258057\n",
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 6, Loss: 2.302889347076416\n",
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 7, Loss: 2.300825357437134\n",
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 8, Loss: 2.2984256744384766\n",
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 9, Loss: 2.295379400253296\n",
      "torch.Size([16, 32, 32])\n",
      "torch.Size([16, 32, 1])\n",
      "torch.Size([16, 32])\n",
      "Epoch 10, Loss: 2.2926602363586426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantAwareModel(\n",
       "  (conv1): Conv1d(\n",
       "    3, 16, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0134]), zero_point=tensor([0], dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=-1.8524562120437622, max_val=1.574406385421753)\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(\n",
       "    16, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0252]), zero_point=tensor([0], dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=-3.155967950820923, max_val=3.2787346839904785)\n",
       "    )\n",
       "  )\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(\n",
       "    in_features=32, out_features=10, bias=True\n",
       "    (weight_fake_quant): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0014]), zero_point=tensor([1], dtype=torch.int32)\n",
       "      (activation_post_process): MinMaxObserver(min_val=-0.17940011620521545, max_val=0.17425675690174103)\n",
       "    )\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0045]), zero_point=tensor([0], dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=-0.8726767897605896, max_val=0.28589972853660583)\n",
       "    )\n",
       "  )\n",
       "  (quant1): QuantStub(\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0264]), zero_point=tensor([0], dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=-3.721123218536377, max_val=3.0184314250946045)\n",
       "    )\n",
       "  )\n",
       "  (dequant1): DeQuantStub()\n",
       "  (quant2): QuantStub(\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0317]), zero_point=tensor([0], dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=0.0, max_val=8.09404468536377)\n",
       "    )\n",
       "  )\n",
       "  (dequant2): DeQuantStub()\n",
       "  (quant3): QuantStub(\n",
       "    (activation_post_process): FakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0040]), zero_point=tensor([0], dtype=torch.int32)\n",
       "      (activation_post_process): CustomObserver(min_val=0.0, max_val=1.0241080522537231)\n",
       "    )\n",
       "  )\n",
       "  (dequant3): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy training loop\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dummy data\n",
    "inputs = torch.randn(16, 3, 32).to(device)\n",
    "targets = torch.randint(0, 10, (16,)).to(device)\n",
    "\n",
    "# Training with fake quantization\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Move the model back to CPU for folding Batch Normalization layers\n",
    "model.to('cpu')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_batch_norm(conv, bn):\n",
    "    # Fold BatchNorm parameters into Convolution layer\n",
    "    with torch.no_grad():\n",
    "        scale_factor = bn.weight / torch.sqrt(bn.running_var + bn.eps)\n",
    "        conv.weight.copy_(conv.weight * scale_factor.reshape([-1, 1, 1]))\n",
    "        if conv.bias is None:\n",
    "            conv.bias = torch.nn.Parameter(torch.zeros(conv.weight.size(0), dtype=conv.weight.dtype, device=conv.weight.device))\n",
    "        conv.bias.copy_((conv.bias - bn.running_mean) * scale_factor + bn.bias)\n",
    "    return conv\n",
    "\n",
    "# Fold BatchNorm layers\n",
    "model.conv1 = fold_batch_norm(model.conv1, model.bn1)\n",
    "model.conv2 = fold_batch_norm(model.conv2, model.bn2)\n",
    "\n",
    "# Remove BatchNorm layers\n",
    "model.bn1 = None\n",
    "model.bn2 = None\n",
    "\n",
    "# Adjust the forward pass to remove Batch Normalization layers\n",
    "def new_forward(self, x):\n",
    "    x = self.quant1(x)  # Quantize the input\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu1(x)\n",
    "    x = self.dequant1(x)\n",
    "    x = self.quant2(x)  # Quantize the input\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = self.dequant2(x)\n",
    "    x = self.pool(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.quant3(x)  # Quantize the input\n",
    "    x = self.fc(x)\n",
    "    x = self.dequant3(x)  # Dequantize the output\n",
    "    return x\n",
    "\n",
    "model.forward = new_forward.__get__(model, QuantAwareModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantAwareModel(\n",
       "  (conv1): QuantizedConv1d(3, 16, kernel_size=(3,), stride=(1,), scale=0.013438677415251732, zero_point=0, padding=(1,))\n",
       "  (bn1): None\n",
       "  (relu1): ReLU()\n",
       "  (conv2): QuantizedConv1d(16, 32, kernel_size=(3,), stride=(1,), scale=0.025234129279851913, zero_point=0, padding=(1,))\n",
       "  (bn2): None\n",
       "  (relu2): ReLU()\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): QuantizedLinear(in_features=32, out_features=10, scale=0.004543437156826258, zero_point=0, qscheme=torch.per_tensor_affine)\n",
       "  (quant1): Quantize(scale=tensor([0.0264]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant1): DeQuantize()\n",
       "  (quant2): Quantize(scale=tensor([0.0317]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant2): DeQuantize()\n",
       "  (quant3): Quantize(scale=tensor([0.0040]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant3): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model back to CPU for quantized inference\n",
    "# Convert the trained model to a quantized version\n",
    "model.eval()\n",
    "quant.convert(model, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantAwareModel(\n",
      "  (conv1): QuantizedConv1d(3, 16, kernel_size=(3,), stride=(1,), scale=0.013438677415251732, zero_point=0, padding=(1,))\n",
      "  (bn1): None\n",
      "  (relu1): ReLU()\n",
      "  (conv2): QuantizedConv1d(16, 32, kernel_size=(3,), stride=(1,), scale=0.025234129279851913, zero_point=0, padding=(1,))\n",
      "  (bn2): None\n",
      "  (relu2): ReLU()\n",
      "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): QuantizedLinear(in_features=32, out_features=10, scale=0.004543437156826258, zero_point=0, qscheme=torch.per_tensor_affine)\n",
      "  (quant1): Quantize(scale=tensor([0.0264]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (dequant1): DeQuantize()\n",
      "  (quant2): Quantize(scale=tensor([0.0317]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (dequant2): DeQuantize()\n",
      "  (quant3): Quantize(scale=tensor([0.0040]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (dequant3): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Inspect the quantization parameters (scale and zero-point) for each layer\n",
    "for name, module in model.named_modules():\n",
    "    if hasattr(module, 'weight_fake_quant'):\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Weight scale: {module.weight_fake_quant.scale}\")\n",
    "        print(f\"Weight zero-point: {module.weight_fake_quant.zero_point}\")\n",
    "    if hasattr(module, 'activation_post_process'):\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Activation scale: {module.activation_post_process.scale}\")\n",
    "        print(f\"Activation zero-point: {module.activation_post_process.zero_point}\")\n",
    "\n",
    "\n",
    "print( model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Integer values after conv1:\n",
      "[[[33  0 57 ...  0 31  0]\n",
      "  [ 0  0  7 ... 23 36  0]\n",
      "  [ 0 67  5 ... 75 17  0]\n",
      "  ...\n",
      "  [ 0 10  0 ...  0  0 41]\n",
      "  [11 24  0 ...  8  0  0]\n",
      "  [ 0  7  0 ... 21  0  0]]\n",
      "\n",
      " [[ 0  3  0 ...  0  0  0]\n",
      "  [ 0 24 50 ...  0 59 61]\n",
      "  [ 0  0 18 ...  0  0 43]\n",
      "  ...\n",
      "  [ 0  0 43 ... 45 58  0]\n",
      "  [25  2 15 ...  0  0 96]\n",
      "  [ 0  0  0 ...  0  0  0]]\n",
      "\n",
      " [[ 1  0  0 ...  0  6  3]\n",
      "  [ 0  1  0 ...  0  2  0]\n",
      "  [ 0  0  9 ...  0  0  0]\n",
      "  ...\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [46 13 38 ... 19  0  0]\n",
      "  [ 0  0  0 ...  0  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0  0 24 ...  0  0  0]\n",
      "  [ 5 28  7 ... 53  0 24]\n",
      "  [ 0 10 22 ... 65  0  4]\n",
      "  ...\n",
      "  [ 0  0  0 ...  0 83  0]\n",
      "  [55 33  0 ...  0  0 66]\n",
      "  [ 0  0  0 ...  0  0  0]]\n",
      "\n",
      " [[14  0  0 ...  0  0  0]\n",
      "  [ 3  0  0 ...  0  4  0]\n",
      "  [45 51 10 ...  0  0 13]\n",
      "  ...\n",
      "  [ 0  0 41 ... 24  0  0]\n",
      "  [62 12  0 ...  0 44 33]\n",
      "  [ 0  0  0 ...  0  0  0]]\n",
      "\n",
      " [[ 0  1  0 ... 31  0  0]\n",
      "  [60  8 20 ...  0 49 55]\n",
      "  [ 0 24 27 ...  0 43 12]\n",
      "  ...\n",
      "  [ 0  0 23 ...  0 85  0]\n",
      "  [ 2  5  0 ...  0 14 47]\n",
      "  [ 0  0  0 ...  0  0  0]]]\n",
      "\n",
      "Integer values after conv2:\n",
      "[[[ 0  0  0 ...  0  0  0]\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [ 0  0  0 ...  0  0  9]\n",
      "  ...\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [ 0  6  0 ...  6  0  0]]\n",
      "\n",
      " [[ 0  0  0 ...  0  0  0]\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [ 4  6 14 ...  2 15  1]\n",
      "  ...\n",
      "  [ 0  0  1 ...  0  0  0]\n",
      "  [ 2  0 11 ...  0 13  1]\n",
      "  [ 3  0  4 ...  9  0  0]]\n",
      "\n",
      " [[ 0  4  0 ...  0  0  0]\n",
      "  [ 0  0  0 ...  3  0  0]\n",
      "  [ 1  0  0 ...  0  2  7]\n",
      "  ...\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [ 2  0  5 ...  0  0  0]\n",
      "  [ 0  0  0 ...  5  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0  0  0 ...  0  0  3]\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [ 1  0  0 ...  0  5  2]\n",
      "  ...\n",
      "  [ 0  0  0 ... 21  0  0]\n",
      "  [ 0  6  0 ...  0  0  0]\n",
      "  [ 0  0  0 ...  0  4  0]]\n",
      "\n",
      " [[ 0  0  0 ...  0  0  0]\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [ 0  0  0 ... 12  1  0]\n",
      "  ...\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [ 1  0  0 ...  0  2  3]\n",
      "  [ 0  0 15 ...  0  0  0]]\n",
      "\n",
      " [[ 0  0  0 ...  0  0  0]\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [17  1  0 ...  0  8  6]\n",
      "  ...\n",
      "  [ 0  0  0 ...  0  0  0]\n",
      "  [ 9  0  0 ...  0  5  0]\n",
      "  [ 3  0  4 ...  4 12  0]]]\n"
     ]
    }
   ],
   "source": [
    "def hook_conv1(module, input, output):\n",
    "    if output.is_quantized:\n",
    "        print('hello')\n",
    "        model.int_output1 = output.int_repr().cpu().numpy()  # Capture integer values after conv1\n",
    "\n",
    "def hook_conv2(module, input, output):\n",
    "    if output.is_quantized:\n",
    "        model.int_output2 = output.int_repr().cpu().numpy()  # Capture integer values after conv2\n",
    "\n",
    "# Register hooks\n",
    "model.conv1.register_forward_hook(hook_conv1)\n",
    "model.conv2.register_forward_hook(hook_conv2)\n",
    "\n",
    "# Dummy input data for inference on CPU\n",
    "inputs_cpu = inputs.to('cpu')\n",
    "\n",
    "# Perform inference and print integer outputs\n",
    "with torch.no_grad():\n",
    "    _ = model(inputs_cpu)\n",
    "\n",
    "print(\"Integer values after conv1:\")\n",
    "print(model.int_output1)\n",
    "\n",
    "print(\"\\nInteger values after conv2:\")\n",
    "print(model.int_output2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_conv_lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
